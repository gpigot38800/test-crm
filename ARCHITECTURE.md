# üèóÔ∏è Architecture Technique - Dashboard CRM

**Version** : 1.0
**Date** : 2025-02-05
**Statut** : MVP Phase 1

---

## üìã Vue d'Ensemble

Dashboard CRM pour fondateur avec objectif de maximiser le volume et la valeur des deals, con√ßu pour √©voluer vers un usage multi-utilisateurs dans 6-12 mois.

### Principes Directeurs
- ‚úÖ **Rapidit√© de d√©veloppement** : MVP en 3 jours
- ‚úÖ **Simplicit√© architecturale** : Stack Python monolithique
- ‚úÖ **√âvolutivit√© pr√©par√©e** : PostgreSQL d√®s le d√©part
- ‚úÖ **Co√ªts ma√Ætris√©s** : Tiers gratuits pour d√©marrage

---

## üéØ Stack Technique Retenue

### Frontend & Backend
- **Framework** : Streamlit 1.32+
- **Langage** : Python 3.11+
- **Architecture** : Monolithe (frontend + backend dans app.py)

**Justification** :
- D√©veloppement rapide (pure Python, pas de JS/HTML/CSS)
- Excellente int√©gration data science (Pandas, NumPy natifs)
- Adapt√© pour 1-50 utilisateurs
- Migration future possible vers React si n√©cessaire (> 100 users)

### Base de Donn√©es
- **SGBD** : PostgreSQL 15+
- **H√©bergement** : Neon.tech (tier gratuit)
  - Limite : 10 GB storage
  - Serverless avec scaling automatique
  - Connection string : `postgresql://user:pass@host/dbname`
- **ORM** : SQLAlchemy 2.0+
- **Driver** : psycopg3

**Justification** :
- Multi-users ready (vs SQLite limit√© √† 1 write)
- Scalabilit√© illimit√©e (tera-octets support√©s)
- √âvite migration database dans 6 mois
- Permissions granulaires natives (GRANT/REVOKE)
- Standard universel (portabilit√© garantie)

### Data Processing & Visualisation
- **Data manipulation** : Pandas 2.2+, NumPy 1.26+
- **Graphiques** : Plotly 5.18+ (interactivit√©)
- **CSV parsing** : Pandas `read_csv()` (natif)
- **Calculs m√©tier** : Python pur (probabilit√©s, pond√©rations)

### D√©ploiement
- **Phase MVP** : Local uniquement
  - Lancement : `streamlit run app.py`
  - Acc√®s : `http://localhost:8501`
  - Pas de conteneur pour simplifier dev
- **Phase Production (future)** :
  - Docker + Railway/Render
  - Variables d'environnement (.env)
  - CI/CD GitHub Actions

---

## üìÅ Structure Projet

```
crm-dashboard/
‚îú‚îÄ‚îÄ app.py                      # Point d'entr√©e Streamlit
‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances Python
‚îú‚îÄ‚îÄ .env.example               # Template variables environnement
‚îú‚îÄ‚îÄ .gitignore                 # Exclure .env, __pycache__, etc.
‚îÇ
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ connection.py          # Connection pool PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ models.py              # Mod√®les SQLAlchemy (table Deals)
‚îÇ   ‚îú‚îÄ‚îÄ crud.py                # Op√©rations CRUD
‚îÇ   ‚îî‚îÄ‚îÄ init_schema.sql        # Sch√©ma SQL initial
‚îÇ
‚îú‚îÄ‚îÄ business_logic/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ calculators.py         # Calcul probabilit√©s & pond√©rations
‚îÇ   ‚îú‚îÄ‚îÄ validators.py          # Validation donn√©es (CSV, formulaires)
‚îÇ   ‚îî‚îÄ‚îÄ filters.py             # Logique filtrage (secteur, statut, dates)
‚îÇ
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ kpi_cards.py           # M√©triques flash (panier moyen, pipe total)
‚îÇ   ‚îú‚îÄ‚îÄ sector_analysis.py     # Graphique barres par secteur
‚îÇ   ‚îú‚îÄ‚îÄ funnel_chart.py        # Pipeline pond√©r√© (entonnoir)
‚îÇ   ‚îú‚îÄ‚îÄ deadline_table.py      # Liste deals avec √©ch√©ances
‚îÇ   ‚îî‚îÄ‚îÄ csv_uploader.py        # Interface upload CSV
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ formatters.py          # Formatage ‚Ç¨, %, dates fran√ßaises
‚îÇ   ‚îî‚îÄ‚îÄ constants.py           # Constantes (statuts, probabilit√©s)
‚îÇ
‚îî‚îÄ‚îÄ tests/                      # Tests unitaires (future Phase 2)
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ test_calculators.py
    ‚îî‚îÄ‚îÄ test_validators.py
```

---

## üóÑÔ∏è Sch√©ma Base de Donn√©es

### Table `deals`

| Colonne | Type | Contraintes | Description |
|---------|------|-------------|-------------|
| `id` | SERIAL | PRIMARY KEY | Identifiant unique auto-incr√©ment√© |
| `client` | VARCHAR(255) | NOT NULL | Nom du prospect/entreprise |
| `statut` | VARCHAR(50) | NOT NULL | Prospect, Qualifi√©, N√©gociation, Gagn√© |
| `montant_brut` | DECIMAL(12,2) | NOT NULL | Valeur totale du deal (‚Ç¨) |
| `probabilite` | DECIMAL(3,2) | NOT NULL | 0.10, 0.30, 0.70, 1.00 (auto-calcul√©) |
| `valeur_ponderee` | DECIMAL(12,2) | GENERATED | `montant_brut * probabilite` |
| `secteur` | VARCHAR(100) | | Secteur d'activit√© (ex: Tech, Sport) |
| `date_echeance` | DATE | | Date de cl√¥ture pr√©vue |
| `assignee` | VARCHAR(100) | | Commercial responsable |
| `notes` | TEXT | | D√©tails additionnels |
| `created_at` | TIMESTAMP | DEFAULT NOW() | Date de cr√©ation |
| `updated_at` | TIMESTAMP | DEFAULT NOW() | Derni√®re modification |

### Index
```sql
CREATE INDEX idx_deals_statut ON deals(statut);
CREATE INDEX idx_deals_secteur ON deals(secteur);
CREATE INDEX idx_deals_date_echeance ON deals(date_echeance);
CREATE INDEX idx_deals_assignee ON deals(assignee);
```

### R√®gles M√©tier (Triggers)
```sql
-- Auto-update updated_at
CREATE TRIGGER update_deals_updated_at
  BEFORE UPDATE ON deals
  FOR EACH ROW
  EXECUTE FUNCTION update_timestamp();

-- Auto-calculate probabilite from statut
CREATE TRIGGER calculate_probabilite
  BEFORE INSERT OR UPDATE ON deals
  FOR EACH ROW
  EXECUTE FUNCTION set_probabilite_from_statut();
```

---

## üîß Configuration Environnement

### Variables d'Environnement (.env)

```bash
# Database
DATABASE_URL=postgresql://user:password@ep-cool-name.us-east-2.aws.neon.tech/crm_db?sslmode=require

# Application
APP_ENV=development  # development | production
DEBUG_MODE=true

# Streamlit Config
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_HEADLESS=false
```

### Fichier requirements.txt

```txt
# Core
streamlit==1.32.0
python-dotenv==1.0.1

# Database
sqlalchemy==2.0.27
psycopg[binary]==3.1.18
alembic==1.13.1  # Migrations (Phase 2)

# Data Processing
pandas==2.2.1
numpy==1.26.4

# Visualisation
plotly==5.18.0

# Utils
python-dateutil==2.9.0
```

---

## üìä Fonctionnalit√©s MVP (Phase 1)

### 1. Import CSV
- Upload fichier `crm_prospects_demo.csv`
- Mapping colonnes automatique
- Validation donn√©es (montants > 0, dates valides)
- Calcul automatique probabilit√©s selon statut
- Insertion batch en PostgreSQL

### 2. KPIs Flash
- **Pipeline pond√©r√© total** : Somme `valeur_ponderee`
- **Panier moyen** : Moyenne `montant_brut`
- **Taux de conversion** : `(Deals gagn√©s / Total deals) * 100`
- **Nombre de deals** : Count par statut

### 3. Analyse par Secteur
- Graphique barres horizontales (Plotly)
- Montant total par secteur
- Top 5 secteurs √† plus haut panier moyen
- Filtrable par statut

### 4. Gestion √âch√©ances
- Liste des deals avec `date_echeance`
- **Alertes rouges** : √âch√©ances d√©pass√©es (date < aujourd'hui)
- **√Ä venir** : Prochains 30 jours
- Tri par date croissante

### 5. Navigation & Filtres
- Sidebar Streamlit :
  - Filtre par statut (multiselect)
  - Filtre par secteur (multiselect)
  - Filtre par commercial (multiselect)
  - Range de dates (date_input)
- Bouton "Reset filtres"

---

## üöÄ Roadmap d'√âvolution

### Phase 1 : MVP (Actuel) - 3 jours
- ‚úÖ Import CSV
- ‚úÖ KPIs flash
- ‚úÖ Analyse secteur
- ‚úÖ Gestion √©ch√©ances
- ‚úÖ Filtres basiques

### Phase 2 : V1 (3-6 mois) - +1 semaine
- [ ] Saisie manuelle (formulaire CRUD)
- [ ] Authentification basique (streamlit-authenticator)
- [ ] Performance commerciale (analyse par assignee)
- [ ] Export Excel/PDF
- [ ] Filtres avanc√©s (recherche textuelle)

### Phase 3 : V2 (6-12 mois) - +1 semaine
- [ ] Vitesse de vente (m√©triques temporelles)
- [ ] Simulateur "What-If" (impact +10% panier moyen)
- [ ] Relances automatiques (deals froids > 10j)
- [ ] Notifications email (√©ch√©ances J-7)
- [ ] API REST (FastAPI endpoints)

### Phase 4 : Scale (12-18 mois) - Si n√©cessaire
- [ ] Migration React + FastAPI (si > 100 users)
- [ ] Permissions granulaires (RBAC)
- [ ] Mobile app (React Native)
- [ ] Int√©grations tierces (Zapier, Stripe)

---

## üîê S√©curit√©

### Phase MVP (Usage Solo)
- ‚ö†Ô∏è **Pas d'authentification** : Acc√®s local uniquement
- ‚úÖ **Connection PostgreSQL SSL** : `sslmode=require`
- ‚úÖ **Variables environnement** : Credentials hors Git
- ‚úÖ **Validation inputs** : Protection SQL injection (SQLAlchemy)

### Phase Production (Future)
- [ ] Authentification multi-utilisateurs
- [ ] Row-Level Security (RLS) PostgreSQL
- [ ] HTTPS obligatoire
- [ ] Rate limiting
- [ ] Logs audit trail

---

## ‚ö° Performance

### Optimisations Streamlit
```python
# Cache donn√©es database (refresh 5 min)
@st.cache_data(ttl=300)
def load_deals():
    return pd.read_sql_query("SELECT * FROM deals", engine)

# Cache calculs lourds
@st.cache_data
def calculate_sector_analysis(df):
    return df.groupby('secteur')['montant_brut'].sum()
```

### Optimisations PostgreSQL
- Index sur colonnes filtr√©es (`statut`, `secteur`, `date_echeance`)
- Connection pooling (SQLAlchemy `pool_size=5`)
- Query pagination (LIMIT/OFFSET pour grandes tables)

### Limites Connues
- Streamlit recharge script complet √† chaque interaction
- Adapt√© pour < 50 utilisateurs simultan√©s
- Tables > 100k lignes : pr√©voir agr√©gations en DB

---

## üì¶ D√©ploiement

### Local Development
```bash
# 1. Setup environnement
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 2. Installer d√©pendances
pip install -r requirements.txt

# 3. Configurer .env
cp .env.example .env
# √âditer DATABASE_URL avec credentials Neon

# 4. Initialiser database
python -m database.init_schema

# 5. Lancer app
streamlit run app.py
```

### Production (Future Phase 2)
```bash
# 1. Build Docker image
docker build -t crm-dashboard .

# 2. Deploy Railway/Render
railway up  # ou render deploy

# 3. Variables environnement
railway variables set DATABASE_URL=postgresql://...
```

---

## üß™ Tests & Qualit√©

### Phase MVP
- ‚ö†Ô∏è Pas de tests automatis√©s (priorisation vitesse)
- ‚úÖ Tests manuels :
  - Import CSV avec donn√©es demo
  - V√©rification calculs (probabilit√©s, pond√©rations)
  - Test filtres et interactions

### Phase 2 (Future)

#### Tests Unitaires (Python)
```bash
# Tests unitaires
pytest tests/

# Coverage
pytest --cov=business_logic --cov-report=html
```

#### Tests End-to-End (Playwright)

**Installation** :
```bash
# Installer Playwright
pip install pytest-playwright
playwright install chromium

# Ou avec npm (si Node.js disponible)
npm install -D @playwright/test
npx playwright install
```

**Structure Tests E2E** :
```
tests/
‚îú‚îÄ‚îÄ e2e/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py              # Configuration pytest
‚îÇ   ‚îú‚îÄ‚îÄ test_dashboard_flow.py   # Parcours utilisateur complet
‚îÇ   ‚îú‚îÄ‚îÄ test_csv_upload.py       # Tests upload CSV
‚îÇ   ‚îú‚îÄ‚îÄ test_filters.py          # Tests filtres sidebar
‚îÇ   ‚îî‚îÄ‚îÄ test_kpis.py             # Validation m√©triques
‚îî‚îÄ‚îÄ fixtures/
    ‚îî‚îÄ‚îÄ test_data.csv            # Donn√©es de test
```

**Exemple Test** :
```python
# tests/e2e/test_dashboard_flow.py
import pytest
from playwright.sync_api import Page, expect

@pytest.fixture(scope="session")
def streamlit_url():
    return "http://localhost:8501"

def test_homepage_loads(page: Page, streamlit_url):
    """V√©rifie que la page principale charge correctement"""
    page.goto(streamlit_url)
    expect(page).to_have_title("CRM Dashboard")

    # V√©rifier pr√©sence KPIs
    expect(page.locator("text=Pipeline Pond√©r√©")).to_be_visible()
    expect(page.locator("text=Panier Moyen")).to_be_visible()

def test_csv_upload_workflow(page: Page, streamlit_url):
    """Test complet d'upload CSV"""
    page.goto(streamlit_url)

    # Upload fichier
    page.locator("input[type='file']").set_input_files("tests/fixtures/test_data.csv")

    # Attendre traitement
    page.wait_for_selector("text=Import r√©ussi", timeout=5000)

    # V√©rifier donn√©es affich√©es
    expect(page.locator("text=10 deals import√©s")).to_be_visible()

def test_filters_interaction(page: Page, streamlit_url):
    """Test filtres sidebar"""
    page.goto(streamlit_url)

    # Ouvrir sidebar si ferm√©e
    if not page.locator(".stSidebar").is_visible():
        page.locator("[data-testid='stSidebarCollapse']").click()

    # S√©lectionner filtre statut
    page.locator("text=Statut").click()
    page.locator("text=N√©gociation").click()

    # V√©rifier mise √† jour tableau
    page.wait_for_timeout(1000)  # Attendre rerun Streamlit
    expect(page.locator(".stDataFrame")).to_contain_text("N√©gociation")

def test_kpi_calculations(page: Page, streamlit_url):
    """Validation calculs m√©triques"""
    page.goto(streamlit_url)

    # R√©cup√©rer valeur pipeline pond√©r√©
    pipeline_value = page.locator("[data-testid='stMetricValue']").first.inner_text()

    # V√©rifier format (doit contenir ‚Ç¨)
    assert "‚Ç¨" in pipeline_value
    assert pipeline_value != "0 ‚Ç¨"
```

**Configuration pytest** :
```python
# tests/e2e/conftest.py
import pytest
import subprocess
import time

@pytest.fixture(scope="session", autouse=True)
def start_streamlit():
    """D√©marre Streamlit avant les tests"""
    process = subprocess.Popen(
        ["streamlit", "run", "app.py", "--server.headless", "true"],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )

    # Attendre d√©marrage
    time.sleep(5)

    yield

    # Arr√™ter √† la fin
    process.terminate()
    process.wait()
```

**Ex√©cution** :
```bash
# Tests E2E complets
pytest tests/e2e/

# Mode headed (voir navigateur)
pytest tests/e2e/ --headed

# Tests sp√©cifiques
pytest tests/e2e/test_csv_upload.py -v

# Screenshots sur √©chec
pytest tests/e2e/ --screenshot on-failure
```

**Points d'Attention Streamlit** :
- Streamlit recharge la page √† chaque interaction ‚Üí utiliser `page.wait_for_timeout()` ou attendre s√©lecteurs
- Data-testids : Streamlit g√©n√®re des IDs stables (`data-testid="stMetricValue"`)
- Sidebar : Peut √™tre cach√©e sur mobile ‚Üí v√©rifier visibilit√©
- File uploader : Utiliser `set_input_files()` pour upload programmatique

---

## üìö Documentation Additionnelle

### R√©f√©rences Techniques
- [Streamlit Docs](https://docs.streamlit.io/)
- [SQLAlchemy 2.0 Guide](https://docs.sqlalchemy.org/en/20/)
- [Neon PostgreSQL](https://neon.tech/docs)
- [Plotly Python](https://plotly.com/python/)

### Fichiers Li√©s
- `PRD.md` : Sp√©cifications fonctionnelles compl√®tes
- `README.md` : Instructions setup et usage
- `.env.example` : Template configuration

---

## ü§ù D√©cisions Architecturales Cl√©s

### 1. Pourquoi Streamlit plut√¥t que React ?
- **Temps dev** : 3 jours vs 15-20 jours
- **Complexit√©** : Python monolithe vs frontend/backend s√©par√©s
- **Usage** : < 50 users parfaitement adapt√©
- **Migration** : Possible vers React si > 100 users dans 12-18 mois

### 2. Pourquoi PostgreSQL plut√¥t que SQLite ?
- **Multi-users** : √âvolution pr√©vue 6-12 mois
- **Volume** : Support tera-octets vs 1 GB SQLite
- **Int√©grations** : LISTEN/NOTIFY pour webhooks futures
- **Migration √©vit√©e** : +1 jour dev maintenant = -5 jours migration future

### 3. Pourquoi Neon plut√¥t que Supabase/Railway ?
- **Simplicit√©** : Setup 5 minutes, z√©ro configuration
- **G√©n√©rosit√©** : 10 GB gratuit (vs 500 MB Supabase)
- **Focus** : Pure PostgreSQL, pas de services annexes
- **Serverless** : Scaling automatique inclus

### 4. Pourquoi pas d'authentification au MVP ?
- **Scope** : Usage solo fondateur Phase 1
- **Vitesse** : √âconomise 1-2 jours dev
- **Flexibilit√©** : Ajout Phase 2 avec streamlit-authenticator (simple)
- **S√©curit√©** : Acc√®s local = pas d'exposition internet

---

## ‚úÖ Checklist de D√©marrage

- [ ] Cr√©er compte Neon.tech
- [ ] Provisionner database PostgreSQL
- [ ] Cloner/cr√©er structure projet
- [ ] Configurer .env avec DATABASE_URL
- [ ] Installer d√©pendances Python
- [ ] Initialiser sch√©ma database
- [ ] Tester connection PostgreSQL
- [ ] Importer CSV demo
- [ ] Valider calculs automatiques
- [ ] Lancer Streamlit localement

**Temps estim√©** : 3 jours (MVP complet)

---

**Contact** : Pour questions/clarifications sur architecture
**Derni√®re mise √† jour** : 2025-02-05
